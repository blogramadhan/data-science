{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 4.3: Statistical Analysis\n",
    "\n",
    "**Durasi:** 60 menit  \n",
    "**Dataset:** RUP 2025\n",
    "\n",
    "## Tujuan Pembelajaran\n",
    "- Descriptive statistics dan measures\n",
    "- Correlation analysis\n",
    "- Distribution analysis dan testing\n",
    "- Hypothesis testing basics\n",
    "- A/B testing fundamentals\n",
    "- Statistical inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from scipy import stats\n",
    "from scipy.stats import normaltest, shapiro, ttest_ind, chi2_contingency, f_oneway\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Visualization settings\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('Set2')\n",
    "\n",
    "print(\"âœ… Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data_path = Path('../../../datasets/rup/RUP-PaketPenyedia-Terumumkan-2025.parquet')\n",
    "df = pd.read_parquet(data_path)\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nNumeric columns:\")\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "for col in numeric_cols:\n",
    "    print(f\"  - {col}\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Descriptive Statistics\n",
    "\n",
    "### 3.1 Central Tendency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'pagu' in df.columns:\n",
    "    # Calculate central tendency measures\n",
    "    mean_pagu = df['pagu'].mean()\n",
    "    median_pagu = df['pagu'].median()\n",
    "    mode_pagu = df['pagu'].mode()[0] if len(df['pagu'].mode()) > 0 else None\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"CENTRAL TENDENCY MEASURES - PAGU\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Mean (Rata-rata):   Rp {mean_pagu:,.0f}\")\n",
    "    print(f\"Median (Nilai Tengah): Rp {median_pagu:,.0f}\")\n",
    "    print(f\"Mode (Nilai Terbanyak): Rp {mode_pagu:,.0f}\" if mode_pagu else \"Mode: N/A\")\n",
    "    \n",
    "    # Visualize\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    \n",
    "    # Filter for better visualization\n",
    "    pagu_filtered = df[df['pagu'] < df['pagu'].quantile(0.95)]['pagu'] / 1_000_000\n",
    "    \n",
    "    ax.hist(pagu_filtered, bins=50, color='lightblue', edgecolor='black', alpha=0.7)\n",
    "    ax.axvline(mean_pagu/1_000_000, color='red', linestyle='--', linewidth=2, \n",
    "               label=f'Mean: {mean_pagu/1_000_000:.1f}M')\n",
    "    ax.axvline(median_pagu/1_000_000, color='green', linestyle='--', linewidth=2,\n",
    "               label=f'Median: {median_pagu/1_000_000:.1f}M')\n",
    "    \n",
    "    ax.set_title('Distribution of Pagu with Central Tendency Measures', \n",
    "                 fontsize=14, fontweight='bold', pad=20)\n",
    "    ax.set_xlabel('Pagu (Juta Rupiah)', fontweight='bold')\n",
    "    ax.set_ylabel('Frequency', fontweight='bold')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Dispersion (Variability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'pagu' in df.columns:\n",
    "    # Calculate dispersion measures\n",
    "    variance = df['pagu'].var()\n",
    "    std_dev = df['pagu'].std()\n",
    "    min_val = df['pagu'].min()\n",
    "    max_val = df['pagu'].max()\n",
    "    range_val = max_val - min_val\n",
    "    \n",
    "    # Coefficient of variation\n",
    "    cv = (std_dev / mean_pagu) * 100\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"DISPERSION MEASURES - PAGU\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Variance:              {variance:,.0f}\")\n",
    "    print(f\"Standard Deviation:    Rp {std_dev:,.0f}\")\n",
    "    print(f\"Minimum:               Rp {min_val:,.0f}\")\n",
    "    print(f\"Maximum:               Rp {max_val:,.0f}\")\n",
    "    print(f\"Range:                 Rp {range_val:,.0f}\")\n",
    "    print(f\"Coefficient of Variation: {cv:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Percentiles & Quartiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'pagu' in df.columns:\n",
    "    # Calculate percentiles\n",
    "    percentiles = [5, 10, 25, 50, 75, 90, 95, 99]\n",
    "    pagu_percentiles = df['pagu'].quantile([p/100 for p in percentiles])\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"PERCENTILES - PAGU\")\n",
    "    print(\"=\" * 60)\n",
    "    for p, val in zip(percentiles, pagu_percentiles):\n",
    "        print(f\"P{p:2d}: Rp {val:>15,.0f}\")\n",
    "    \n",
    "    # Quartiles and IQR\n",
    "    Q1 = df['pagu'].quantile(0.25)\n",
    "    Q2 = df['pagu'].quantile(0.50)\n",
    "    Q3 = df['pagu'].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    print(f\"\\nQuartiles:\")\n",
    "    print(f\"Q1 (25%): Rp {Q1:,.0f}\")\n",
    "    print(f\"Q2 (50%): Rp {Q2:,.0f}\")\n",
    "    print(f\"Q3 (75%): Rp {Q3:,.0f}\")\n",
    "    print(f\"IQR:      Rp {IQR:,.0f}\")\n",
    "    \n",
    "    # Visualize box plot\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    \n",
    "    # Filter for better visualization\n",
    "    pagu_filtered = df[df['pagu'] < df['pagu'].quantile(0.95)]['pagu'] / 1_000_000\n",
    "    \n",
    "    bp = ax.boxplot(pagu_filtered, vert=False, patch_artist=True,\n",
    "                    boxprops=dict(facecolor='lightblue', alpha=0.7),\n",
    "                    medianprops=dict(color='red', linewidth=2),\n",
    "                    whiskerprops=dict(linewidth=1.5),\n",
    "                    capprops=dict(linewidth=1.5))\n",
    "    \n",
    "    ax.set_xlabel('Pagu (Juta Rupiah)', fontweight='bold')\n",
    "    ax.set_title('Box Plot: Pagu Distribution (Quartiles)', fontsize=14, fontweight='bold', pad=20)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add quartile labels\n",
    "    ax.text(Q1/1_000_000, 1.15, f'Q1\\n{Q1/1_000_000:.1f}M', ha='center', fontsize=9, fontweight='bold')\n",
    "    ax.text(Q2/1_000_000, 1.15, f'Q2\\n{Q2/1_000_000:.1f}M', ha='center', fontsize=9, fontweight='bold')\n",
    "    ax.text(Q3/1_000_000, 1.15, f'Q3\\n{Q3/1_000_000:.1f}M', ha='center', fontsize=9, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Shape Measures (Skewness & Kurtosis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'pagu' in df.columns:\n",
    "    # Calculate shape measures\n",
    "    skewness = df['pagu'].skew()\n",
    "    kurtosis = df['pagu'].kurt()\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"SHAPE MEASURES - PAGU\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Skewness: {skewness:.3f}\")\n",
    "    \n",
    "    if skewness > 0:\n",
    "        print(\"  â†’ Positive skew (right-skewed): tail extends to the right\")\n",
    "    elif skewness < 0:\n",
    "        print(\"  â†’ Negative skew (left-skewed): tail extends to the left\")\n",
    "    else:\n",
    "        print(\"  â†’ Symmetric distribution\")\n",
    "    \n",
    "    print(f\"\\nKurtosis: {kurtosis:.3f}\")\n",
    "    \n",
    "    if kurtosis > 0:\n",
    "        print(\"  â†’ Leptokurtic: heavy tails, more outliers\")\n",
    "    elif kurtosis < 0:\n",
    "        print(\"  â†’ Platykurtic: light tails, fewer outliers\")\n",
    "    else:\n",
    "        print(\"  â†’ Mesokurtic: normal distribution-like\")\n",
    "    \n",
    "    # Visualize\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Original distribution\n",
    "    pagu_filtered = df[df['pagu'] < df['pagu'].quantile(0.95)]['pagu'] / 1_000_000\n",
    "    axes[0].hist(pagu_filtered, bins=50, color='coral', edgecolor='black', alpha=0.7)\n",
    "    axes[0].set_title(f'Original Distribution\\nSkewness: {skewness:.2f}, Kurtosis: {kurtosis:.2f}',\n",
    "                      fontweight='bold')\n",
    "    axes[0].set_xlabel('Pagu (Juta Rp)')\n",
    "    axes[0].set_ylabel('Frequency')\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Log-transformed (to reduce skewness)\n",
    "    pagu_log = np.log1p(df['pagu'])\n",
    "    axes[1].hist(pagu_log, bins=50, color='lightgreen', edgecolor='black', alpha=0.7)\n",
    "    axes[1].set_title(f'Log-Transformed\\nSkewness: {pagu_log.skew():.2f}, Kurtosis: {pagu_log.kurt():.2f}',\n",
    "                      fontweight='bold')\n",
    "    axes[1].set_xlabel('Log(Pagu)')\n",
    "    axes[1].set_ylabel('Frequency')\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Correlation Analysis\n",
    "\n",
    "### 4.1 Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select numeric columns\n",
    "numeric_df = df.select_dtypes(include=[np.number])\n",
    "\n",
    "if len(numeric_df.columns) > 1:\n",
    "    # Calculate correlation matrix\n",
    "    corr_matrix = numeric_df.corr()\n",
    "    \n",
    "    print(\"Correlation Matrix:\")\n",
    "    print(corr_matrix)\n",
    "    \n",
    "    # Visualize heatmap\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    \n",
    "    sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='coolwarm', center=0,\n",
    "                square=True, linewidths=1, cbar_kws={\"shrink\": 0.8}, ax=ax)\n",
    "    \n",
    "    ax.set_title('Correlation Matrix - Numeric Variables', fontsize=14, fontweight='bold', pad=20)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Only one numeric column available. Need at least 2 for correlation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Pearson vs Spearman Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(numeric_df.columns) >= 2:\n",
    "    # Get first two numeric columns\n",
    "    col1, col2 = numeric_df.columns[:2]\n",
    "    \n",
    "    # Remove missing values\n",
    "    data_clean = numeric_df[[col1, col2]].dropna()\n",
    "    \n",
    "    if len(data_clean) > 0:\n",
    "        # Pearson correlation (linear relationship)\n",
    "        pearson_corr, pearson_p = stats.pearsonr(data_clean[col1], data_clean[col2])\n",
    "        \n",
    "        # Spearman correlation (monotonic relationship)\n",
    "        spearman_corr, spearman_p = stats.spearmanr(data_clean[col1], data_clean[col2])\n",
    "        \n",
    "        print(\"=\" * 60)\n",
    "        print(f\"CORRELATION ANALYSIS: {col1} vs {col2}\")\n",
    "        print(\"=\" * 60)\n",
    "        print(f\"Pearson Correlation:  {pearson_corr:.4f} (p-value: {pearson_p:.4e})\")\n",
    "        print(f\"Spearman Correlation: {spearman_corr:.4f} (p-value: {spearman_p:.4e})\")\n",
    "        \n",
    "        # Interpretation\n",
    "        if abs(pearson_corr) < 0.3:\n",
    "            strength = \"Weak\"\n",
    "        elif abs(pearson_corr) < 0.7:\n",
    "            strength = \"Moderate\"\n",
    "        else:\n",
    "            strength = \"Strong\"\n",
    "        \n",
    "        direction = \"Positive\" if pearson_corr > 0 else \"Negative\"\n",
    "        print(f\"\\nInterpretation: {strength} {direction} correlation\")\n",
    "        \n",
    "        if pearson_p < 0.05:\n",
    "            print(\"Result is statistically significant (p < 0.05)\")\n",
    "        else:\n",
    "            print(\"Result is NOT statistically significant (p >= 0.05)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Distribution Analysis\n",
    "\n",
    "### 5.1 Normality Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'pagu' in df.columns:\n",
    "    # Sample data (normality tests work better with smaller samples)\n",
    "    sample = df['pagu'].sample(min(5000, len(df)), random_state=42)\n",
    "    \n",
    "    # Shapiro-Wilk test (good for n < 5000)\n",
    "    if len(sample) < 5000:\n",
    "        shapiro_stat, shapiro_p = shapiro(sample)\n",
    "        print(\"Shapiro-Wilk Test:\")\n",
    "        print(f\"  Statistic: {shapiro_stat:.6f}\")\n",
    "        print(f\"  P-value: {shapiro_p:.6e}\")\n",
    "        if shapiro_p < 0.05:\n",
    "            print(\"  â†’ Data is NOT normally distributed (p < 0.05)\")\n",
    "        else:\n",
    "            print(\"  â†’ Data appears normally distributed (p >= 0.05)\")\n",
    "    \n",
    "    # D'Agostino-Pearson test\n",
    "    dagostino_stat, dagostino_p = normaltest(sample)\n",
    "    print(\"\\nD'Agostino-Pearson Test:\")\n",
    "    print(f\"  Statistic: {dagostino_stat:.6f}\")\n",
    "    print(f\"  P-value: {dagostino_p:.6e}\")\n",
    "    if dagostino_p < 0.05:\n",
    "        print(\"  â†’ Data is NOT normally distributed (p < 0.05)\")\n",
    "    else:\n",
    "        print(\"  â†’ Data appears normally distributed (p >= 0.05)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Q-Q Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'pagu' in df.columns:\n",
    "    # Create Q-Q plot\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "    \n",
    "    # Q-Q plot for original data\n",
    "    stats.probplot(sample, dist=\"norm\", plot=axes[0])\n",
    "    axes[0].set_title('Q-Q Plot: Original Pagu Data', fontweight='bold')\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Q-Q plot for log-transformed data\n",
    "    sample_log = np.log1p(sample)\n",
    "    stats.probplot(sample_log, dist=\"norm\", plot=axes[1])\n",
    "    axes[1].set_title('Q-Q Plot: Log-Transformed Pagu Data', fontweight='bold')\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nQ-Q Plot Interpretation:\")\n",
    "    print(\"  - Points close to red line â†’ data follows normal distribution\")\n",
    "    print(\"  - Points deviate from line â†’ data NOT normally distributed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Hypothesis Testing\n",
    "\n",
    "### 6.1 T-Test: Comparing Two Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare pagu between two metode pengadaan\n",
    "if 'metode_pengadaan' in df.columns and 'pagu' in df.columns:\n",
    "    # Get top 2 methods\n",
    "    top_methods = df['metode_pengadaan'].value_counts().head(2).index\n",
    "    \n",
    "    group1 = df[df['metode_pengadaan'] == top_methods[0]]['pagu'].dropna()\n",
    "    group2 = df[df['metode_pengadaan'] == top_methods[1]]['pagu'].dropna()\n",
    "    \n",
    "    # Independent t-test\n",
    "    t_stat, p_value = ttest_ind(group1, group2)\n",
    "    \n",
    "    print(\"=\" * 70)\n",
    "    print(\"INDEPENDENT T-TEST\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"Group 1: {top_methods[0]}\")\n",
    "    print(f\"  Sample size: {len(group1)}\")\n",
    "    print(f\"  Mean: Rp {group1.mean():,.0f}\")\n",
    "    print(f\"  Std: Rp {group1.std():,.0f}\")\n",
    "    \n",
    "    print(f\"\\nGroup 2: {top_methods[1]}\")\n",
    "    print(f\"  Sample size: {len(group2)}\")\n",
    "    print(f\"  Mean: Rp {group2.mean():,.0f}\")\n",
    "    print(f\"  Std: Rp {group2.std():,.0f}\")\n",
    "    \n",
    "    print(f\"\\nT-statistic: {t_stat:.4f}\")\n",
    "    print(f\"P-value: {p_value:.6f}\")\n",
    "    \n",
    "    print(\"\\nHypothesis:\")\n",
    "    print(\"  H0: No difference in mean pagu between groups\")\n",
    "    print(\"  H1: Significant difference in mean pagu between groups\")\n",
    "    \n",
    "    print(\"\\nConclusion (Î± = 0.05):\")\n",
    "    if p_value < 0.05:\n",
    "        print(f\"  âœ“ Reject H0: There IS a significant difference (p = {p_value:.6f})\")\n",
    "    else:\n",
    "        print(f\"  âœ— Fail to reject H0: No significant difference (p = {p_value:.6f})\")\n",
    "    \n",
    "    # Visualize\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    \n",
    "    # Filter for better visualization\n",
    "    g1_filtered = group1[group1 < group1.quantile(0.95)] / 1_000_000\n",
    "    g2_filtered = group2[group2 < group2.quantile(0.95)] / 1_000_000\n",
    "    \n",
    "    ax.hist([g1_filtered, g2_filtered], bins=30, label=[top_methods[0], top_methods[1]], \n",
    "            alpha=0.6, edgecolor='black')\n",
    "    ax.set_title('Distribution Comparison: Pagu by Metode', fontsize=14, fontweight='bold', pad=20)\n",
    "    ax.set_xlabel('Pagu (Juta Rupiah)', fontweight='bold')\n",
    "    ax.set_ylabel('Frequency', fontweight='bold')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 ANOVA: Comparing Multiple Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare pagu across multiple metode pengadaan\n",
    "if 'metode_pengadaan' in df.columns and 'pagu' in df.columns:\n",
    "    # Get top 5 methods\n",
    "    top5_methods = df['metode_pengadaan'].value_counts().head(5).index\n",
    "    \n",
    "    # Create groups\n",
    "    groups = [df[df['metode_pengadaan'] == method]['pagu'].dropna() for method in top5_methods]\n",
    "    \n",
    "    # Perform ANOVA\n",
    "    f_stat, p_value = f_oneway(*groups)\n",
    "    \n",
    "    print(\"=\" * 70)\n",
    "    print(\"ONE-WAY ANOVA\")\n",
    "    print(\"=\" * 70)\n",
    "    print(\"Comparing pagu across 5 metode pengadaan\")\n",
    "    print(f\"\\nF-statistic: {f_stat:.4f}\")\n",
    "    print(f\"P-value: {p_value:.6e}\")\n",
    "    \n",
    "    print(\"\\nHypothesis:\")\n",
    "    print(\"  H0: All groups have the same mean\")\n",
    "    print(\"  H1: At least one group has a different mean\")\n",
    "    \n",
    "    print(\"\\nConclusion (Î± = 0.05):\")\n",
    "    if p_value < 0.05:\n",
    "        print(f\"  âœ“ Reject H0: At least one group is significantly different\")\n",
    "    else:\n",
    "        print(f\"  âœ— Fail to reject H0: No significant difference\")\n",
    "    \n",
    "    # Group statistics\n",
    "    print(\"\\nGroup Statistics:\")\n",
    "    for i, method in enumerate(top5_methods):\n",
    "        print(f\"\\n{i+1}. {method}\")\n",
    "        print(f\"   N: {len(groups[i])}\")\n",
    "        print(f\"   Mean: Rp {groups[i].mean():,.0f}\")\n",
    "        print(f\"   Std: Rp {groups[i].std():,.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Chi-Square Test: Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chi-square test for independence between categorical variables\n",
    "cat_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "if len(cat_cols) >= 2:\n",
    "    # Take first two categorical columns\n",
    "    col1, col2 = cat_cols[0], cat_cols[1]\n",
    "    \n",
    "    # Create contingency table\n",
    "    # Limit to top categories for readability\n",
    "    top_cat1 = df[col1].value_counts().head(3).index\n",
    "    top_cat2 = df[col2].value_counts().head(3).index\n",
    "    \n",
    "    df_filtered = df[df[col1].isin(top_cat1) & df[col2].isin(top_cat2)]\n",
    "    contingency_table = pd.crosstab(df_filtered[col1], df_filtered[col2])\n",
    "    \n",
    "    # Perform chi-square test\n",
    "    chi2, p_value, dof, expected = chi2_contingency(contingency_table)\n",
    "    \n",
    "    print(\"=\" * 70)\n",
    "    print(\"CHI-SQUARE TEST OF INDEPENDENCE\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"Variables: {col1} vs {col2}\")\n",
    "    \n",
    "    print(\"\\nContingency Table:\")\n",
    "    print(contingency_table)\n",
    "    \n",
    "    print(f\"\\nChi-square statistic: {chi2:.4f}\")\n",
    "    print(f\"P-value: {p_value:.6f}\")\n",
    "    print(f\"Degrees of freedom: {dof}\")\n",
    "    \n",
    "    print(\"\\nHypothesis:\")\n",
    "    print(\"  H0: Variables are independent\")\n",
    "    print(\"  H1: Variables are associated/dependent\")\n",
    "    \n",
    "    print(\"\\nConclusion (Î± = 0.05):\")\n",
    "    if p_value < 0.05:\n",
    "        print(f\"  âœ“ Reject H0: Variables are associated\")\n",
    "    else:\n",
    "        print(f\"  âœ— Fail to reject H0: Variables appear independent\")\n",
    "    \n",
    "    # Visualize\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    contingency_table.plot(kind='bar', ax=ax, rot=45)\n",
    "    ax.set_title(f'Contingency Table: {col1} vs {col2}', fontsize=12, fontweight='bold', pad=20)\n",
    "    ax.set_ylabel('Count', fontweight='bold')\n",
    "    ax.legend(title=col2)\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. A/B Testing Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate A/B test scenario\n",
    "# Example: Compare conversion rates between two methods\n",
    "\n",
    "if 'metode_pengadaan' in df.columns:\n",
    "    # Get two groups\n",
    "    top2_methods = df['metode_pengadaan'].value_counts().head(2).index\n",
    "    \n",
    "    # Simulate \"conversion\" - let's say packages with pagu > median are \"converted\"\n",
    "    median_pagu = df['pagu'].median()\n",
    "    df['converted'] = (df['pagu'] > median_pagu).astype(int)\n",
    "    \n",
    "    # Group A and B\n",
    "    group_a = df[df['metode_pengadaan'] == top2_methods[0]]\n",
    "    group_b = df[df['metode_pengadaan'] == top2_methods[1]]\n",
    "    \n",
    "    # Calculate conversion rates\n",
    "    conv_a = group_a['converted'].mean()\n",
    "    conv_b = group_b['converted'].mean()\n",
    "    \n",
    "    # Sample sizes\n",
    "    n_a = len(group_a)\n",
    "    n_b = len(group_b)\n",
    "    \n",
    "    print(\"=\" * 70)\n",
    "    print(\"A/B TEST EXAMPLE\")\n",
    "    print(\"=\" * 70)\n",
    "    print(\"Scenario: Comparing 'conversion rate' (pagu > median) between methods\")\n",
    "    \n",
    "    print(f\"\\nGroup A: {top2_methods[0]}\")\n",
    "    print(f\"  Sample size: {n_a}\")\n",
    "    print(f\"  Conversions: {group_a['converted'].sum()}\")\n",
    "    print(f\"  Conversion rate: {conv_a*100:.2f}%\")\n",
    "    \n",
    "    print(f\"\\nGroup B: {top2_methods[1]}\")\n",
    "    print(f\"  Sample size: {n_b}\")\n",
    "    print(f\"  Conversions: {group_b['converted'].sum()}\")\n",
    "    print(f\"  Conversion rate: {conv_b*100:.2f}%\")\n",
    "    \n",
    "    # Statistical test\n",
    "    from scipy.stats import chi2_contingency\n",
    "    \n",
    "    contingency = pd.DataFrame({\n",
    "        'Converted': [group_a['converted'].sum(), group_b['converted'].sum()],\n",
    "        'Not Converted': [n_a - group_a['converted'].sum(), n_b - group_b['converted'].sum()]\n",
    "    }, index=['Group A', 'Group B'])\n",
    "    \n",
    "    chi2, p_value, dof, expected = chi2_contingency(contingency)\n",
    "    \n",
    "    print(f\"\\nChi-square test:\")\n",
    "    print(f\"  Chi2: {chi2:.4f}\")\n",
    "    print(f\"  P-value: {p_value:.6f}\")\n",
    "    \n",
    "    print(\"\\nConclusion (Î± = 0.05):\")\n",
    "    if p_value < 0.05:\n",
    "        winner = 'A' if conv_a > conv_b else 'B'\n",
    "        print(f\"  âœ“ Significant difference! Group {winner} performs better\")\n",
    "    else:\n",
    "        print(f\"  âœ— No significant difference between groups\")\n",
    "    \n",
    "    # Calculate lift\n",
    "    lift = ((conv_b - conv_a) / conv_a) * 100 if conv_a > 0 else 0\n",
    "    print(f\"\\nLift: {lift:+.2f}%\")\n",
    "    \n",
    "    # Visualize\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    groups = ['Group A\\n' + top2_methods[0][:30], 'Group B\\n' + top2_methods[1][:30]]\n",
    "    rates = [conv_a * 100, conv_b * 100]\n",
    "    colors = ['#3498db', '#e74c3c']\n",
    "    \n",
    "    bars = ax.bar(groups, rates, color=colors, alpha=0.7, edgecolor='black')\n",
    "    ax.set_ylabel('Conversion Rate (%)', fontweight='bold')\n",
    "    ax.set_title('A/B Test: Conversion Rate Comparison', fontsize=14, fontweight='bold', pad=20)\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar, rate in zip(bars, rates):\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{rate:.2f}%',\n",
    "                ha='center', va='bottom', fontweight='bold', fontsize=12)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'pagu' in df.columns:\n",
    "    print(\"=\" * 70)\n",
    "    print(\"STATISTICAL ANALYSIS SUMMARY\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    print(\"\\n1. DESCRIPTIVE STATISTICS\")\n",
    "    print(df['pagu'].describe())\n",
    "    \n",
    "    print(f\"\\n2. DISTRIBUTION CHARACTERISTICS\")\n",
    "    print(f\"   Skewness: {df['pagu'].skew():.3f}\")\n",
    "    print(f\"   Kurtosis: {df['pagu'].kurt():.3f}\")\n",
    "    \n",
    "    print(f\"\\n3. VARIABILITY\")\n",
    "    print(f\"   CV: {(df['pagu'].std()/df['pagu'].mean())*100:.2f}%\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    \n",
    "    print(\"\\nðŸ“Š KEY INSIGHTS:\")\n",
    "    print(\"   - Use these statistics to understand your data\")\n",
    "    print(\"   - Identify patterns and anomalies\")\n",
    "    print(\"   - Make data-driven decisions\")\n",
    "    print(\"   - Compare different groups statistically\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Key Takeaways\n",
    "\n",
    "### Descriptive Statistics:\n",
    "- âœ… Central Tendency: Mean, Median, Mode\n",
    "- âœ… Dispersion: Variance, Std Dev, Range\n",
    "- âœ… Percentiles & Quartiles (IQR)\n",
    "- âœ… Shape: Skewness & Kurtosis\n",
    "\n",
    "### Correlation:\n",
    "- âœ… Pearson correlation (linear)\n",
    "- âœ… Spearman correlation (monotonic)\n",
    "- âœ… Correlation matrix & heatmap\n",
    "\n",
    "### Distribution:\n",
    "- âœ… Normality tests (Shapiro-Wilk, D'Agostino)\n",
    "- âœ… Q-Q plots\n",
    "- âœ… Histogram analysis\n",
    "\n",
    "### Hypothesis Testing:\n",
    "- âœ… T-test (two groups)\n",
    "- âœ… ANOVA (multiple groups)\n",
    "- âœ… Chi-square (categorical)\n",
    "- âœ… P-value interpretation\n",
    "\n",
    "### A/B Testing:\n",
    "- âœ… Conversion rate comparison\n",
    "- âœ… Statistical significance\n",
    "- âœ… Lift calculation\n",
    "\n",
    "### Important Concepts:\n",
    "- **P-value < 0.05**: Result is statistically significant\n",
    "- **Correlation â‰  Causation**: Strong correlation doesn't imply causation\n",
    "- **Sample size matters**: Larger samples = more reliable results\n",
    "- **Check assumptions**: Each test has prerequisites"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
