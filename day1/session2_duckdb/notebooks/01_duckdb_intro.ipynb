{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 2.1: Introduction to DuckDB\n",
    "Bootcamp Data Analysis - Python, DuckDB & Streamlit\n",
    "\n",
    "## Topics:\n",
    "1. What is DuckDB?\n",
    "2. Setup and first connection\n",
    "3. Basic SQL operations\n",
    "4. Loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to DuckDB\n",
    "\n",
    "DuckDB adalah embedded analytical database yang:\n",
    "- Fast untuk analytical queries\n",
    "- Zero-dependency (no server needed)\n",
    "- Support standard SQL\n",
    "- Easy integration dengan Python/Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DuckDB version: 1.4.1\n"
     ]
    }
   ],
   "source": [
    "import duckdb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"DuckDB version:\", duckdb.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Connected to DuckDB (in-memory)\n"
     ]
    }
   ],
   "source": [
    "# In-memory database\n",
    "conn = duckdb.connect(':memory:')\n",
    "print(\"‚úÖ Connected to DuckDB (in-memory)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or persistent database\n",
    "# conn = duckdb.connect('my_database.db')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Basic SQL Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Table 'employees' created\n"
     ]
    }
   ],
   "source": [
    "# Create table\n",
    "conn.execute(\"\"\"\n",
    "    CREATE TABLE employees (\n",
    "        id INTEGER,\n",
    "        name VARCHAR,\n",
    "        department VARCHAR,\n",
    "        salary INTEGER\n",
    "    )\n",
    "\"\"\")\n",
    "\n",
    "print(\"‚úÖ Table 'employees' created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Data inserted\n"
     ]
    }
   ],
   "source": [
    "# Insert data\n",
    "conn.execute(\"\"\"\n",
    "    INSERT INTO employees VALUES\n",
    "        (1, 'Alice', 'Engineering', 75000),\n",
    "        (2, 'Bob', 'Sales', 65000),\n",
    "        (3, 'Charlie', 'Engineering', 80000),\n",
    "        (4, 'David', 'Marketing', 60000),\n",
    "        (5, 'Eve', 'Engineering', 85000)\n",
    "\"\"\")\n",
    "\n",
    "print(\"‚úÖ Data inserted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä All Employees:\n",
      "   id     name   department  salary\n",
      "0   1    Alice  Engineering   75000\n",
      "1   2      Bob        Sales   65000\n",
      "2   3  Charlie  Engineering   80000\n",
      "3   4    David    Marketing   60000\n",
      "4   5      Eve  Engineering   85000\n"
     ]
    }
   ],
   "source": [
    "# Simple SELECT\n",
    "result = conn.execute(\"SELECT * FROM employees\").df()\n",
    "print(\"\\nüìä All Employees:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üë®‚Äçüíª Engineering Department:\n",
      "   id     name   department  salary\n",
      "0   1    Alice  Engineering   75000\n",
      "1   3  Charlie  Engineering   80000\n",
      "2   5      Eve  Engineering   85000\n"
     ]
    }
   ],
   "source": [
    "# WHERE clause\n",
    "result = conn.execute(\"\"\"\n",
    "    SELECT * FROM employees\n",
    "    WHERE department = 'Engineering'\n",
    "\"\"\").df()\n",
    "print(\"\\nüë®‚Äçüíª Engineering Department:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üí∞ Employees by Salary (Highest first):\n",
      "   id     name   department  salary\n",
      "0   5      Eve  Engineering   85000\n",
      "1   3  Charlie  Engineering   80000\n",
      "2   1    Alice  Engineering   75000\n",
      "3   2      Bob        Sales   65000\n",
      "4   4    David    Marketing   60000\n"
     ]
    }
   ],
   "source": [
    "# ORDER BY\n",
    "result = conn.execute(\"\"\"\n",
    "    SELECT * FROM employees\n",
    "    ORDER BY salary DESC\n",
    "\"\"\").df()\n",
    "print(\"\\nüí∞ Employees by Salary (Highest first):\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Department Statistics:\n",
      "    department  employee_count  avg_salary  max_salary\n",
      "0  Engineering               3     80000.0       85000\n",
      "1        Sales               1     65000.0       65000\n",
      "2    Marketing               1     60000.0       60000\n"
     ]
    }
   ],
   "source": [
    "# Aggregations\n",
    "result = conn.execute(\"\"\"\n",
    "    SELECT\n",
    "        department,\n",
    "        COUNT(*) as employee_count,\n",
    "        AVG(salary) as avg_salary,\n",
    "        MAX(salary) as max_salary\n",
    "    FROM employees\n",
    "    GROUP BY department\n",
    "    ORDER BY avg_salary DESC\n",
    "\"\"\").df()\n",
    "print(\"\\nüìä Department Statistics:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Loading Data from Files\n",
    "\n",
    "DuckDB can read files directly without loading into memory first!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Found dataset: /home/rizko/coding/python/project/data-science/datasets/rup/RUP-PaketPenyedia-Terumumkan-2025.parquet\n",
      "\n",
      "üìä RUP Data (first 10 rows):\n",
      "   tahun_anggaran kd_klpd                  nama_klpd jenis_klpd  kd_satker  \\\n",
      "0            2025    D197  Provinsi Kalimantan Barat   PROVINSI     264455   \n",
      "1            2025    D197  Provinsi Kalimantan Barat   PROVINSI     264456   \n",
      "2            2025    D197  Provinsi Kalimantan Barat   PROVINSI     264456   \n",
      "3            2025    D197  Provinsi Kalimantan Barat   PROVINSI     264456   \n",
      "4            2025    D197  Provinsi Kalimantan Barat   PROVINSI     264456   \n",
      "\n",
      "            kd_satker_str                                        nama_satker  \\\n",
      "0  1.02.0.00.0.00.03.0000         RUMAH SAKIT JIWA PROVINSI KALIMANTAN BARAT   \n",
      "1  1.03.0.00.0.00.01.0000  DINAS PEKERJAAN UMUM DAN PENATAAN RUANG PROVIN...   \n",
      "2  1.03.0.00.0.00.01.0000  DINAS PEKERJAAN UMUM DAN PENATAAN RUANG PROVIN...   \n",
      "3  1.03.0.00.0.00.01.0000  DINAS PEKERJAAN UMUM DAN PENATAAN RUANG PROVIN...   \n",
      "4  1.03.0.00.0.00.01.0000  DINAS PEKERJAAN UMUM DAN PENATAAN RUANG PROVIN...   \n",
      "\n",
      "     kd_rup                                         nama_paket        pagu  \\\n",
      "0  53540979           Belanja Bahan Makanan dan Minuman Pasien  7700000000   \n",
      "1  53688068  Perencanaan Rehabilitasi Gedung UPT Pengujian ...   300000000   \n",
      "2  53699505  PENGAWASAN TEKNIS PENGGANTIAN/PEMBANGUNAN JEMB...  1200000000   \n",
      "3  53700150  PENGAWASAN TEKNIS PENINGKATAN JALAN TANJUNG  M...  1200000000   \n",
      "4  53700183  PENGAWASAN TEKNIS PENINGKATAN JALAN MARAU  AIR...  1500000000   \n",
      "\n",
      "   ...  status_umumkan_rup status_dikecualikan alasan_dikecualikan  \\\n",
      "0  ...          Terumumkan               False                       \n",
      "1  ...          Terumumkan               False                None   \n",
      "2  ...          Terumumkan               False                None   \n",
      "3  ...          Terumumkan               False                None   \n",
      "4  ...          Terumumkan               False                None   \n",
      "\n",
      "  tahun_pertama kode_rup_tahun_pertama nomor_kontrak spp_aspek_ekonomi  \\\n",
      "0          None                   None          None             False   \n",
      "1          None                   None          None             False   \n",
      "2          None                   None          None              True   \n",
      "3          None                   None          None              True   \n",
      "4          None                   None          None              True   \n",
      "\n",
      "  spp_aspek_sosial spp_aspek_lingkungan _event_date  \n",
      "0            False                False  2025-11-05  \n",
      "1            False                False  2025-11-05  \n",
      "2             True                 True  2025-11-05  \n",
      "3             True                 True  2025-11-05  \n",
      "4             True                 True  2025-11-05  \n",
      "\n",
      "[5 rows x 48 columns]\n",
      "\n",
      "üìà Total records in RUP dataset: 16,430\n",
      "\n",
      "üìã Dataset Columns:\n",
      "               column_name column_type null   key default extra\n",
      "0           tahun_anggaran      BIGINT  YES  None    None  None\n",
      "1                  kd_klpd     VARCHAR  YES  None    None  None\n",
      "2                nama_klpd     VARCHAR  YES  None    None  None\n",
      "3               jenis_klpd     VARCHAR  YES  None    None  None\n",
      "4                kd_satker      BIGINT  YES  None    None  None\n",
      "5            kd_satker_str     VARCHAR  YES  None    None  None\n",
      "6              nama_satker     VARCHAR  YES  None    None  None\n",
      "7                   kd_rup      BIGINT  YES  None    None  None\n",
      "8               nama_paket     VARCHAR  YES  None    None  None\n",
      "9                     pagu      BIGINT  YES  None    None  None\n",
      "10     kd_metode_pengadaan      BIGINT  YES  None    None  None\n",
      "11        metode_pengadaan     VARCHAR  YES  None    None  None\n",
      "12      kd_jenis_pengadaan     VARCHAR  YES  None    None  None\n",
      "13         jenis_pengadaan     VARCHAR  YES  None    None  None\n",
      "14          status_pradipa     VARCHAR  YES  None    None  None\n",
      "15              status_pdn     VARCHAR  YES  None    None  None\n",
      "16              status_ukm     VARCHAR  YES  None    None  None\n",
      "17          alasan_non_ukm     VARCHAR  YES  None    None  None\n",
      "18      status_konsolidasi     VARCHAR  YES  None    None  None\n",
      "19              tipe_paket     VARCHAR  YES  None    None  None\n",
      "20        kd_rup_swakelola      BIGINT  YES  None    None  None\n",
      "21            kd_rup_lokal        JSON  YES  None    None  None\n",
      "22        volume_pekerjaan     VARCHAR  YES  None    None  None\n",
      "23       urarian_pekerjaan     VARCHAR  YES  None    None  None\n",
      "24   spesifikasi_pekerjaan     VARCHAR  YES  None    None  None\n",
      "25      tgl_awal_pemilihan        DATE  YES  None    None  None\n",
      "26     tgl_akhir_pemilihan        DATE  YES  None    None  None\n",
      "27        tgl_awal_kontrak        DATE  YES  None    None  None\n",
      "28       tgl_akhir_kontrak        DATE  YES  None    None  None\n",
      "29    tgl_awal_pemanfaatan        DATE  YES  None    None  None\n",
      "30   tgl_akhir_pemanfaatan        DATE  YES  None    None  None\n",
      "31          tgl_buat_paket        DATE  YES  None    None  None\n",
      "32    tgl_pengumuman_paket   TIMESTAMP  YES  None    None  None\n",
      "33                 nip_ppk     VARCHAR  YES  None    None  None\n",
      "34                nama_ppk     VARCHAR  YES  None    None  None\n",
      "35            username_ppk     VARCHAR  YES  None    None  None\n",
      "36        status_aktif_rup     BOOLEAN  YES  None    None  None\n",
      "37       status_delete_rup     BOOLEAN  YES  None    None  None\n",
      "38      status_umumkan_rup     VARCHAR  YES  None    None  None\n",
      "39     status_dikecualikan     BOOLEAN  YES  None    None  None\n",
      "40     alasan_dikecualikan     VARCHAR  YES  None    None  None\n",
      "41           tahun_pertama        JSON  YES  None    None  None\n",
      "42  kode_rup_tahun_pertama        JSON  YES  None    None  None\n",
      "43           nomor_kontrak        JSON  YES  None    None  None\n",
      "44       spp_aspek_ekonomi     BOOLEAN  YES  None    None  None\n",
      "45        spp_aspek_sosial     BOOLEAN  YES  None    None  None\n",
      "46    spp_aspek_lingkungan     BOOLEAN  YES  None    None  None\n",
      "47             _event_date        DATE  YES  None    None  None\n"
     ]
    }
   ],
   "source": [
    "# Find RUP dataset path\n",
    "project_root = Path.cwd().parent.parent.parent\n",
    "data_path = project_root / 'datasets' / 'rup' / 'RUP-PaketPenyedia-Terumumkan-2025.parquet'\n",
    "\n",
    "if data_path.exists():\n",
    "    print(f\"‚úÖ Found dataset: {data_path}\")\n",
    "\n",
    "    # Read Parquet file directly with SQL!\n",
    "    query = f\"\"\"\n",
    "        SELECT * FROM '{data_path}' LIMIT 10\n",
    "    \"\"\"\n",
    "\n",
    "    df = conn.execute(query).df()\n",
    "    print(\"\\nüìä RUP Data (first 10 rows):\")\n",
    "    print(df.head())\n",
    "\n",
    "    # Get row count\n",
    "    count_query = f\"SELECT COUNT(*) as total FROM '{data_path}'\"\n",
    "    total = conn.execute(count_query).fetchone()[0]\n",
    "    print(f\"\\nüìà Total records in RUP dataset: {total:,}\")\n",
    "\n",
    "    # Get column info\n",
    "    info_query = f\"DESCRIBE SELECT * FROM '{data_path}'\"\n",
    "    columns_info = conn.execute(info_query).df()\n",
    "    print(\"\\nüìã Dataset Columns:\")\n",
    "    print(columns_info)\n",
    "\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è Dataset not found at: {data_path}\")\n",
    "    print(\"Creating sample data instead...\")\n",
    "\n",
    "    # Create sample data\n",
    "    sample_data = pd.DataFrame({\n",
    "        'nama_paket': ['Paket A', 'Paket B', 'Paket C'],\n",
    "        'pagu': [1000000000, 2000000000, 1500000000],\n",
    "        'metode_pengadaan': ['Tender', 'Tender', 'Penunjukan Langsung']\n",
    "    })\n",
    "\n",
    "    conn.register('rup_sample', sample_data)\n",
    "    result = conn.execute(\"SELECT * FROM rup_sample\").df()\n",
    "    print(\"\\nüìä Sample RUP Data:\")\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Performance Demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚è±Ô∏è Performance Test...\n",
      "Created dataset with 100,000 rows\n"
     ]
    }
   ],
   "source": [
    "# Create larger dataset for performance test\n",
    "print(\"\\n‚è±Ô∏è Performance Test...\")\n",
    "\n",
    "# Generate sample data\n",
    "np.random.seed(42)\n",
    "n_rows = 100000\n",
    "\n",
    "large_df = pd.DataFrame({\n",
    "    'id': range(n_rows),\n",
    "    'value': np.random.randint(0, 1000, n_rows),\n",
    "    'category': np.random.choice(['A', 'B', 'C', 'D'], n_rows)\n",
    "})\n",
    "\n",
    "print(f\"Created dataset with {n_rows:,} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üêº Pandas aggregation: 0.0098 seconds\n",
      "               sum        mean  count\n",
      "category                             \n",
      "A         12554698  498.083710  25206\n",
      "B         12560836  502.654608  24989\n",
      "C         12493046  500.964231  24938\n",
      "D         12374120  497.612096  24867\n"
     ]
    }
   ],
   "source": [
    "# Method 1: Pandas aggregation\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "pandas_result = large_df.groupby('category')['value'].agg(['sum', 'mean', 'count'])\n",
    "pandas_time = time.time() - start\n",
    "\n",
    "print(f\"\\nüêº Pandas aggregation: {pandas_time:.4f} seconds\")\n",
    "print(pandas_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ü¶Ü DuckDB aggregation: 0.0090 seconds\n",
      "  category         sum        mean  count\n",
      "0        A  12554698.0  498.083710  25206\n",
      "1        B  12560836.0  502.654608  24989\n",
      "2        C  12493046.0  500.964231  24938\n",
      "3        D  12374120.0  497.612096  24867\n"
     ]
    }
   ],
   "source": [
    "# Method 2: DuckDB aggregation\n",
    "conn.register('large_data', large_df)\n",
    "\n",
    "start = time.time()\n",
    "duckdb_result = conn.execute(\"\"\"\n",
    "    SELECT\n",
    "        category,\n",
    "        SUM(value) as sum,\n",
    "        AVG(value) as mean,\n",
    "        COUNT(*) as count\n",
    "    FROM large_data\n",
    "    GROUP BY category\n",
    "\"\"\").df()\n",
    "duckdb_time = time.time() - start\n",
    "\n",
    "print(f\"\\nü¶Ü DuckDB aggregation: {duckdb_time:.4f} seconds\")\n",
    "print(duckdb_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ö° DuckDB is 1.10x faster for this query!\n"
     ]
    }
   ],
   "source": [
    "# Comparison\n",
    "speedup = pandas_time / duckdb_time\n",
    "print(f\"\\n‚ö° DuckDB is {speedup:.2f}x faster for this query!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Exported to employees_export.csv\n"
     ]
    }
   ],
   "source": [
    "# Export to CSV\n",
    "conn.execute(\"\"\"\n",
    "    COPY (\n",
    "        SELECT * FROM employees\n",
    "    ) TO 'employees_export.csv' (HEADER, DELIMITER ',')\n",
    "\"\"\")\n",
    "print(\"‚úÖ Exported to employees_export.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Exported to employees_export.parquet\n"
     ]
    }
   ],
   "source": [
    "# Export to Parquet\n",
    "conn.execute(\"\"\"\n",
    "    COPY (\n",
    "        SELECT * FROM employees\n",
    "    ) TO 'employees_export.parquet' (FORMAT PARQUET)\n",
    "\"\"\")\n",
    "print(\"‚úÖ Exported to employees_export.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìö Key Takeaways\n",
    "\n",
    "1. DuckDB is fast for analytical queries\n",
    "2. Can read files directly without loading to memory\n",
    "3. Standard SQL syntax\n",
    "4. Easy Python integration\n",
    "5. Perfect for local data analysis\n",
    "\n",
    "**Next:** Advanced SQL queries and Pandas integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Connection closed\n"
     ]
    }
   ],
   "source": [
    "# Clean up\n",
    "conn.close()\n",
    "print(\"\\n‚úÖ Connection closed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Session 2.1 Complete!\n",
      "\n",
      "What we learned:\n",
      "- Creating DuckDB connection\n",
      "- Basic SQL operations (SELECT, WHERE, ORDER BY)\n",
      "- Aggregations (COUNT, AVG, MAX, SUM)\n",
      "- Reading files directly (Parquet, CSV)\n",
      "- Performance comparison with Pandas\n",
      "- Export results\n",
      "\n",
      "Next: Advanced SQL queries and Pandas integration\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Summary\n",
    "print(\"\"\"\n",
    "‚úÖ Session 2.1 Complete!\n",
    "\n",
    "What we learned:\n",
    "- Creating DuckDB connection\n",
    "- Basic SQL operations (SELECT, WHERE, ORDER BY)\n",
    "- Aggregations (COUNT, AVG, MAX, SUM)\n",
    "- Reading files directly (Parquet, CSV)\n",
    "- Performance comparison with Pandas\n",
    "- Export results\n",
    "\n",
    "Next: Advanced SQL queries and Pandas integration\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
