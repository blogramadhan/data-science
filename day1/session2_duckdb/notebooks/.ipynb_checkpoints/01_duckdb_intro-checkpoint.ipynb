{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 2.1: Introduction to DuckDB\n",
    "Bootcamp Data Analysis - Python, DuckDB & Streamlit\n",
    "\n",
    "## Topics:\n",
    "1. What is DuckDB?\n",
    "2. Setup and first connection\n",
    "3. Basic SQL operations\n",
    "4. Loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to DuckDB\n",
    "\n",
    "DuckDB adalah embedded analytical database yang:\n",
    "- Fast untuk analytical queries\n",
    "- Zero-dependency (no server needed)\n",
    "- Support standard SQL\n",
    "- Easy integration dengan Python/Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"DuckDB version:\", duckdb.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In-memory database\n",
    "conn = duckdb.connect(':memory:')\n",
    "print(\"‚úÖ Connected to DuckDB (in-memory)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or persistent database\n",
    "# conn = duckdb.connect('my_database.db')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Basic SQL Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create table\n",
    "conn.execute(\"\"\"\n",
    "    CREATE TABLE employees (\n",
    "        id INTEGER,\n",
    "        name VARCHAR,\n",
    "        department VARCHAR,\n",
    "        salary INTEGER\n",
    "    )\n",
    "\"\"\")\n",
    "\n",
    "print(\"‚úÖ Table 'employees' created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert data\n",
    "conn.execute(\"\"\"\n",
    "    INSERT INTO employees VALUES\n",
    "        (1, 'Alice', 'Engineering', 75000),\n",
    "        (2, 'Bob', 'Sales', 65000),\n",
    "        (3, 'Charlie', 'Engineering', 80000),\n",
    "        (4, 'David', 'Marketing', 60000),\n",
    "        (5, 'Eve', 'Engineering', 85000)\n",
    "\"\"\")\n",
    "\n",
    "print(\"‚úÖ Data inserted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple SELECT\n",
    "result = conn.execute(\"SELECT * FROM employees\").df()\n",
    "print(\"\\nüìä All Employees:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WHERE clause\n",
    "result = conn.execute(\"\"\"\n",
    "    SELECT * FROM employees\n",
    "    WHERE department = 'Engineering'\n",
    "\"\"\").df()\n",
    "print(\"\\nüë®‚Äçüíª Engineering Department:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ORDER BY\n",
    "result = conn.execute(\"\"\"\n",
    "    SELECT * FROM employees\n",
    "    ORDER BY salary DESC\n",
    "\"\"\").df()\n",
    "print(\"\\nüí∞ Employees by Salary (Highest first):\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregations\n",
    "result = conn.execute(\"\"\"\n",
    "    SELECT\n",
    "        department,\n",
    "        COUNT(*) as employee_count,\n",
    "        AVG(salary) as avg_salary,\n",
    "        MAX(salary) as max_salary\n",
    "    FROM employees\n",
    "    GROUP BY department\n",
    "    ORDER BY avg_salary DESC\n",
    "\"\"\").df()\n",
    "print(\"\\nüìä Department Statistics:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Loading Data from Files\n",
    "\n",
    "DuckDB can read files directly without loading into memory first!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find RUP dataset path\n",
    "project_root = Path.cwd().parent.parent.parent\n",
    "data_path = project_root / 'datasets' / 'rup' / 'RUP-PaketPenyedia-Terumumkan-2025.parquet'\n",
    "\n",
    "if data_path.exists():\n",
    "    print(f\"‚úÖ Found dataset: {data_path}\")\n",
    "\n",
    "    # Read Parquet file directly with SQL!\n",
    "    query = f\"\"\"\n",
    "        SELECT * FROM '{data_path}' LIMIT 10\n",
    "    \"\"\"\n",
    "\n",
    "    df = conn.execute(query).df()\n",
    "    print(\"\\nüìä RUP Data (first 10 rows):\")\n",
    "    print(df.head())\n",
    "\n",
    "    # Get row count\n",
    "    count_query = f\"SELECT COUNT(*) as total FROM '{data_path}'\"\n",
    "    total = conn.execute(count_query).fetchone()[0]\n",
    "    print(f\"\\nüìà Total records in RUP dataset: {total:,}\")\n",
    "\n",
    "    # Get column info\n",
    "    info_query = f\"DESCRIBE SELECT * FROM '{data_path}'\"\n",
    "    columns_info = conn.execute(info_query).df()\n",
    "    print(\"\\nüìã Dataset Columns:\")\n",
    "    print(columns_info)\n",
    "\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è Dataset not found at: {data_path}\")\n",
    "    print(\"Creating sample data instead...\")\n",
    "\n",
    "    # Create sample data\n",
    "    sample_data = pd.DataFrame({\n",
    "        'nama_paket': ['Paket A', 'Paket B', 'Paket C'],\n",
    "        'pagu': [1000000000, 2000000000, 1500000000],\n",
    "        'metode_pengadaan': ['Tender', 'Tender', 'Penunjukan Langsung']\n",
    "    })\n",
    "\n",
    "    conn.register('rup_sample', sample_data)\n",
    "    result = conn.execute(\"SELECT * FROM rup_sample\").df()\n",
    "    print(\"\\nüìä Sample RUP Data:\")\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Performance Demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create larger dataset for performance test\n",
    "print(\"\\n‚è±Ô∏è Performance Test...\")\n",
    "\n",
    "# Generate sample data\n",
    "np.random.seed(42)\n",
    "n_rows = 100000\n",
    "\n",
    "large_df = pd.DataFrame({\n",
    "    'id': range(n_rows),\n",
    "    'value': np.random.randint(0, 1000, n_rows),\n",
    "    'category': np.random.choice(['A', 'B', 'C', 'D'], n_rows)\n",
    "})\n",
    "\n",
    "print(f\"Created dataset with {n_rows:,} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 1: Pandas aggregation\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "pandas_result = large_df.groupby('category')['value'].agg(['sum', 'mean', 'count'])\n",
    "pandas_time = time.time() - start\n",
    "\n",
    "print(f\"\\nüêº Pandas aggregation: {pandas_time:.4f} seconds\")\n",
    "print(pandas_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 2: DuckDB aggregation\n",
    "conn.register('large_data', large_df)\n",
    "\n",
    "start = time.time()\n",
    "duckdb_result = conn.execute(\"\"\"\n",
    "    SELECT\n",
    "        category,\n",
    "        SUM(value) as sum,\n",
    "        AVG(value) as mean,\n",
    "        COUNT(*) as count\n",
    "    FROM large_data\n",
    "    GROUP BY category\n",
    "\"\"\").df()\n",
    "duckdb_time = time.time() - start\n",
    "\n",
    "print(f\"\\nü¶Ü DuckDB aggregation: {duckdb_time:.4f} seconds\")\n",
    "print(duckdb_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison\n",
    "speedup = pandas_time / duckdb_time\n",
    "print(f\"\\n‚ö° DuckDB is {speedup:.2f}x faster for this query!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to CSV\n",
    "conn.execute(\"\"\"\n",
    "    COPY (\n",
    "        SELECT * FROM employees\n",
    "    ) TO 'employees_export.csv' (HEADER, DELIMITER ',')\n",
    "\"\"\")\n",
    "print(\"‚úÖ Exported to employees_export.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to Parquet\n",
    "conn.execute(\"\"\"\n",
    "    COPY (\n",
    "        SELECT * FROM employees\n",
    "    ) TO 'employees_export.parquet' (FORMAT PARQUET)\n",
    "\"\"\")\n",
    "print(\"‚úÖ Exported to employees_export.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìö Key Takeaways\n",
    "\n",
    "1. DuckDB is fast for analytical queries\n",
    "2. Can read files directly without loading to memory\n",
    "3. Standard SQL syntax\n",
    "4. Easy Python integration\n",
    "5. Perfect for local data analysis\n",
    "\n",
    "**Next:** Advanced SQL queries and Pandas integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up\n",
    "conn.close()\n",
    "print(\"\\n‚úÖ Connection closed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary\n",
    "print(\"\"\"\n",
    "‚úÖ Session 2.1 Complete!\n",
    "\n",
    "What we learned:\n",
    "- Creating DuckDB connection\n",
    "- Basic SQL operations (SELECT, WHERE, ORDER BY)\n",
    "- Aggregations (COUNT, AVG, MAX, SUM)\n",
    "- Reading files directly (Parquet, CSV)\n",
    "- Performance comparison with Pandas\n",
    "- Export results\n",
    "\n",
    "Next: Advanced SQL queries and Pandas integration\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
